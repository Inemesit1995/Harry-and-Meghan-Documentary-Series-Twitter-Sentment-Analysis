{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831cb651-05a9-4e5b-b8ce-32406ec5aac3",
   "metadata": {},
   "source": [
    "# An Analysis of Twitter User's Perception of Harry and Meghan Documentary Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ecda8-c08b-4af0-a3b4-d32cceeec2f0",
   "metadata": {},
   "source": [
    "<a id = 'introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac3c21-7085-46c1-a67b-ebaf60226d2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1. Introduction\n",
    "\n",
    "Harry and Meghan documentary series explores the early days of the courtship between the Duke and Duchess of Sussex and the events that took place that led them feeling forced to relinquish their duties in the royal.\n",
    "I carried out a sentiment analysis to measure the perception of Twitter users and the conversation about the documentary series using Twitter's API and Python library, Tweepy to collect the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcf33d-d61d-4b5f-9c80-3a9fb1d8d0ba",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "<ol>\n",
    "    <li><a href='#introduction'>Introduction</a></li>\n",
    "    <li><a href='#data_collection'>Data Collection</a></li>\n",
    "    <li><a href='#data_preprocessing'>Data Preprocessing</a></li>\n",
    "    <li><a href='#sentiment_analysis'>Sentiment Analysis</a></li>\n",
    "    <li><a href='#sentiment_visualisation'>Sentiment Visualisations</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa435667-d631-4945-a5c4-9690a913b453",
   "metadata": {},
   "source": [
    "<a id = 'data_collection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a0d49-b066-46da-9902-571ef8b3171d",
   "metadata": {},
   "source": [
    "### 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "858cd4b1-f895-450f-a03f-30765c386706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import tweepy \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from advertools.emoji import EMOJI\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf982bc0-78df-443a-a70e-ab79e34898a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Credentials\n",
    "\n",
    "apiKey = '########################'\n",
    "\n",
    "apiKeySecret = '##################################################'\n",
    "\n",
    "accessToken = 'XXXXXXXXX-########################################'\n",
    "\n",
    "accessTokenSecret = '#############################################'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b319c4d-effd-465c-82ff-702786151f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the authentication object\n",
    "authenticate = tweepy.OAuthHandler(apiKey, apiKeySecret)\n",
    "\n",
    "# set accesstoken and accesstokensecret\n",
    "authenticate.set_access_token(accessToken, accessTokenSecret)\n",
    "\n",
    "\n",
    "#create the API object while passing in the auth information\n",
    "api = tweepy.API(authenticate, wait_on_rate_limit=True) #sleeps when API limit is reached\n",
    "sleep_on_rate_limit=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a940ce-d526-4fa3-a7a9-f9d3fdb442c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to download\n",
    "tweet_data = []\n",
    "\n",
    "def get_tweets(search_query, limit_of_tweet):\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=search_query, lang = 'en', count = 100, tweet_mode= 'extended').items(limit_of_tweet)\n",
    "    for tweet in tweets:\n",
    "        data.append([\n",
    "        tweet.id,  # User id\n",
    "        tweet.created_at,       # date and time of tweet\n",
    "        tweet.user.screen_name, # username\n",
    "        tweet.user.location,    # location of the user\n",
    "        tweet.full_text,        # tweet\n",
    "        tweet.retweet_count,    # number of retweets on the tweet\n",
    "        tweet.favorite_count,   # number of likes on the tweet\n",
    "        ])      \n",
    "        \n",
    "# Hashtags to look out for,filter out retweets and replies\n",
    "queryTopic = '#HarryAndMeghanNetfix OR #HarryAndMeghanNetflix OR #MeghanandHarryNetflix OR #HarryandMeghanonNetflix OR #MeghanandHarryonNetflix OR #HarryandMeghan OR #MeghanandHarry OR #PrinceHarry OR #MeghanMarkle'\n",
    "searchQuery = queryTopic + \" -filter:retweets AND -filter:replies\" \n",
    "\n",
    "#  Pass in the paramters\n",
    "get_tweets(searchQuery, 50000)  \n",
    "\n",
    "# Name each column of the dataframe\n",
    "tweet_df = pd.DataFrame(tweet_data, columns = ['Id', 'Date_time_of_time', 'Username', 'Location', 'Tweet',  'Retweet', 'Like']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ccb2e-0c0a-4d56-accf-74812eedb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the dataframe\n",
    "print(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3b9ec-1ffc-4c0d-8403-f5f81f6ff29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract hashtags and remove #\n",
    "def getHashtags(tweet):\n",
    "    # make the lowercase of the tweets\n",
    "    tweet = tweet.lower()  \n",
    "    # Search all words that starts a hashtag\n",
    "    tweet = re.findall(r'\\#\\w+',tweet) \n",
    "    return \" \".join(tweet)\n",
    "\n",
    "# Extract the hashtags by applying the function to the Tweet column \n",
    "tweet_df['Hashtag'] = tweet_df['Tweet'].apply(getHashtags)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d67d3-c0c5-4778-9200-0df2209a5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data elements into a list\n",
    "hashtag_list = tweet_df['Hashtag'].tolist()\n",
    "\n",
    "# Split the hashtags into seperate rows where there is more than one hashtag\n",
    "hashtag = []\n",
    "for item in hashtag_list:\n",
    "    item = item.split()\n",
    "    for i in item:\n",
    "        hashtag.append(i)\n",
    "        \n",
    "# Determine count of all hashtags used\n",
    "counts = Counter(hashtag)\n",
    "hashtag_df = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
    "hashtag_df.columns = ['Hashtag', 'Count']\n",
    "hashtag_df.sort_values(by='Count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47e7bc-210e-4280-9129-2ce40e79395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as a csv file\n",
    "tweet_df.to_csv('HarryandMeghan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827a0b8-3f88-4d73-a6b2-f904523f118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file\n",
    "tweet_df = pd.read_csv('HarryandMeghan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5dbfa-1c21-4ceb-89f5-e3dcf7b9343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the dataframe\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cfc85-6a65-4780-90dc-119057713d0a",
   "metadata": {},
   "source": [
    "<a id = 'data_preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fbc97-0acf-48b9-beb3-47c28fe8808d",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3571d01-848a-4e11-ba9e-53e231a59a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect dataframe\n",
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d02ac-d7d4-4bbe-8c3b-189a9a12b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "tweet_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba35d7f-323b-4ad3-82f3-fa9a0f630f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing locations with \"Unspecified\"\n",
    "tweet_df[\"Location\"] = tweet_df[\"Location\"].fillna('Unspecified')\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5c0ad-408a-4dfa-b96d-0209bfcfef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the missing locations are filled\n",
    "tweet_df[\"Location\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589a3be-5ed1-4ec2-a2c5-11d5893f3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "tweet_df.duplicated(subset='Id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20292d8-80dc-4106-b463-1021ef89673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns \n",
    "tweet_df.drop(tweet_df.columns[[0, 1]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c4d17-6563-434c-b4ab-715be37c8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the dataframe\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1cdcae-133f-4791-8df4-e68ae96ceb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04c5d0-4fe5-4f60-b098-082aeb3464f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61547b4-2266-4c79-87f2-ac141191bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate emoji\n",
    "EMOJI_PATTERN = EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f46e21-ac95-4cb0-9bc5-6d4a9c275bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean the tweets\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    # Remove @ mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) \n",
    "    # Remove symbols\n",
    "    text = re.sub(r'[#:_\\!/]', '', text)\n",
    "    # Remove emojis\n",
    "    text = re.sub(EMOJI_PATTERN, r'', text)\n",
    "    # Remove punctuations\n",
    "    text = re.sub('[()!?]', ' ', text)\n",
    "    text = re.sub('\\[.*?\\]',' ', text)  \n",
    "    # Remove hyperlinks.\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)   \n",
    "    text = re.sub(r'www.\\S+', '', text)\n",
    "    text = re.sub(r'httpst', '', text)\n",
    "    # Remove stopwords \n",
    "    words = [word for word in text.split() if not word in stop_words]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "    \n",
    "    \n",
    "# Cleaning the text\n",
    "tweet_df['Tweet'] = tweet_df['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca1160-9d72-4cf0-b98b-43f92e24ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the clean dataframe\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb762d-b805-4b17-9fbc-d1e7b7957ad3",
   "metadata": {},
   "source": [
    "<a id = 'sentiment_analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed8cf6-444c-4764-a5e1-f7aa3d40662a",
   "metadata": {},
   "source": [
    "### 4. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7ecb1-481f-467d-80e0-220da3ffa89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to obtain the subjecivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to obtain the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Create the subjectivity and polarity columns\n",
    "tweet_df['Subjectivity'] = tweet_df['Tweet'].apply(getSubjectivity)\n",
    "tweet_df['Polarity'] = tweet_df['Tweet'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8433d15-e9a8-43a5-b2f2-91e92505480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the new dataframe with the new columns\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ea718-b461-4aa7-b1b6-001eba0f1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the negative, neutral, positive sentiments\n",
    "def getSentimentAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "# Create a sentiment column and append it to the original dataframe\n",
    "tweet_df['Sentiment'] = tweet_df['Polarity'].apply(getSentimentAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c380861-191c-418d-a44d-b6f398f1b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the new dataframe with the new column\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f810c-5b1e-4b8f-b2b0-caa39d5d0451",
   "metadata": {},
   "source": [
    "<a id = 'sentiment_visualisation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59db993-e107-43fb-9387-bbf8978e692e",
   "metadata": {},
   "source": [
    "### 5. Sentiment Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ffdce-d98a-4f37-bcfa-12c965046ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frames for all sentiments \n",
    "positive_tweet = tweet_df[tweet_df[\"Sentiment\"]==\"Positive\"]\n",
    "neutral_tweet = tweet_df[tweet_df[\"Sentiment\"]==\"Neutral\"]\n",
    "negative_tweet = tweet_df[tweet_df[\"Sentiment\"]==\"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33d85e-7ddb-401e-8fbb-08866ae54f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function count the sentiments and calculate the percentage in a single dataframe\n",
    "def count_values(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100, 2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "\n",
    "# Count_values for sentiment\n",
    "count_values(tweet_df,\"Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa8272-5f16-48c4-a6e1-35b4e7dc0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print positive tweets\n",
    "ptweet = tweet_df[tweet_df.Sentiment == 'Positive']\n",
    "ptweet = ptweet['Tweet']\n",
    "\n",
    "ptweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c4696-2208-4b97-8229-34d3d19fe72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Pie Chart\n",
    "pie_chart = count_values(tweet_df,\"Sentiment\")\n",
    "\n",
    "\n",
    "names= pie_chart.index\n",
    "size= pie_chart[\"Percentage\"]\n",
    "\n",
    "# Create a circle for the centre of the plot\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(size, labels=names, colors=['black','cyan','blue'])\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f4881-6c1e-4d3b-a425-c4e697cb6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the value count\n",
    "tweet_df['Sentiment'].value_counts()\n",
    "\n",
    "# Plot and visualise the counts\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "tweet_df['Sentiment'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80168c-a687-4c03-b6f9-114087afdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the wordcloud using\n",
    "everyword = ' '.join(tweet_df['Tweet'])\n",
    "wordcloud = WordCloud(\n",
    "    stopwords=STOPWORDS,\n",
    "    background_color = 'black',\n",
    "    width = 600,\n",
    "    height = 400,\n",
    "    collocations = False,\n",
    "    max_words = 100,\n",
    "    max_font_size = 400).generate(everyword)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title('Word Cloud for Harry and Meghan Series')\n",
    "plt.savefig(\"Harry_Meghan_wordcloud.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7185d8-211d-4d66-9a62-c8c247926ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframes as csv files to build a dashboard with Power BI\n",
    "tweet_df.to_csv('HarryandMeghan1.csv')\n",
    "\n",
    "hashtag_df.to_csv('hashtags.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
